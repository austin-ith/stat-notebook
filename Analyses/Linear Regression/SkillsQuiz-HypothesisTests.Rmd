---
title: "Skills Quiz: Hypothesis Tests"
output: 
  html_document:
    theme: cerulean
    code_folding: hide
    toc: true
    toc_float: true
---


## Instructions

Use this file to keep a record of your work as you complete the "Skills Quiz: Hypothesis Tests" assignment in Canvas.


----

<!-- Note: The {} after each Problem and Part header allows you to keep track of what work you have completed. Write something like {Done} once you complete each problem and your html file will then show you a nice summary of what you have "done" already. -->


## Problem 1 {}

Install the `Ecdat` library in R: `install.packages("Ecdat")`.

```{r message=FALSE, warning=FALSE}
library(mosaic)
library(tidyverse)
library(Ecdat)
library(pander)
library(car)
```

From `library(Ecdat)` open the `Caschool` data set in R.  As stated in the help file for this data set, this data is a collection of measurements on 420 different school districts from California during the 1998-1999 school year.

The school districts in California offer a reduced-price lunch program. This is in a way, a measure of the poverty of the student body of the school district. We will assume that the higher the percentage of participants, the greater the general level of poverty. The question is, does the poverty level (or at least the percentage of participation in the reduced-lunch program) predict how well the student body will perform overall on a standardized test?

`> ?Caschool`

`> View(Caschool)`

### Part (a) {}

Type out the mathematical equation for this regression model and label both $Y$ and $X$ in the equation.

<div class="YourAnswer">

$$
  \underbrace{Y_i}_\text{Average Test Score} = \beta_0 + \beta_1\underbrace{X_i}_\text{Poverty Level} + \ \epsilon_i \quad where \ \epsilon_i \sim N(0, \sigma^2)
$$
And where Poverty Level is the percent qualifying for reduced-price lunch
</div>


### Part (b) {}
 
Plot a scatterplot of the data with your regression line overlaid. Write out the fitted regression equation.

<div class="YourAnswer">

```{r}
Caschool %>% 
  ggplot(aes(x=mealpct, y = testscr)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Poverty Level\n(Percent qualifying for Reduced-price Lunch)",
       y = "Standardized Test Scores",
       title = "Poverty level and Test Scores") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

caschool.lm <- lm(testscr ~ mealpct, data = Caschool)
summary(caschool.lm) %>% 
  pander()
```

$$
  \hat{Y}_i = 681.43952-0.61029X_i
$$

</div>


### Part (c) {}

Report the test statistics and p-values for the following hypotheses.

$$ 
  \begin{array}{l}
    H_0: \beta_0 = 0 \\
    H_a: \beta_0 \neq 0 \\
  \end{array} \quad 
  \begin{array}{l}
    H_0: \beta_1 = 0 \\
    H_a: \beta_1 \neq 0 \\
  \end{array}
$$

<div class="YourAnswer">

```{r}
summary(caschool.lm) %>% 
  pander()
```

--------------------------------------------
                    T Value       p-value
-------------    ------------   ------------
Intercept =        766.16         <2e-16
Slope =            -35.87         <2e-16
--------------------------------------------

</div> 
 
 
### Part (d) {}


State the slope, y-intercept, and $R^2$ of this regression. Further, provide 95% confidence intervals for the slope and intercept. Interpret the values.

<div class="YourAnswer">

```{r}
summary(caschool.lm) %>% 
  pander()
cv <- qt(((1-.05)/2), 420-2)

```

--------------------------------------
                          Value   
------------      ------------------
Intercept =        681.43952
Slope =                  -0.61029
$R^2$ =                   0.7548
--------------------------------------

This intercept is the value of the predicted test score if the poverty level was 0.
The slope is the predicted rate at which, in this case, test scores drop for every 1 percent increase in poverty level.
The $R^2$ value tells us how well this model fits the data. Approaching 0 meaning that it doesn't fit well at all and approaching 1 meaning that it fits well. As you can see, this model works well. 

With 420 degrees of freedom, our critical value = -0.06274444. Therefore our confidence intervals are:

$$
 \beta_1: \quad -0.61029 \pm `r cv*.01701`
$$
$$
 \beta_0: \quad 681.43952 \pm `r cv*.88943`
$$


</div>


### Part (e) {}

Create a residuals vs fitted-values plot and Q-Q Plot of the residuals for this regression. What do these plots show?

<div class="YourAnswer">

```{r}
par(mfrow=c(1,3))
plot(caschool.lm, which=1)
qqPlot(caschool.lm$residuals, id = FALSE, main = "QQ Plot",
       ylab = "Residuals")
plot(caschool.lm$residuals, main = "Residuals vs Order", xlab="",ylab="Residuals")
```

Constant variance and normality seems to be okay. But linearity and Order seem to be violated.

</div>




----

## Problem 2 {}

Open the `Clothing` data set from library(Ecdat).

Although this data is from 1990, it contains two interesting variables (1) the total `tsales` of the clothing stores and (2) the average number of hours worked per employee during the year, `hourspw`. 

`> ?Clothing`

`> View(Clothing)`

### Part (a) {}

Type out the mathematical equation for this regression model and label both $Y$ and $X$ in the equation.

<div class="YourAnswer">

$$
  \underbrace{Y_i}_\text{Total Sales} = \beta_0 + \beta_1\underbrace{X_i}_\text{Average Hours Worked}
$$

</div>


### Part (b) {}
 
Plot a scatterplot of the data with your regression line overlaid. Write out the fitted regression equation.

<div class="YourAnswer">

```{r}
Clothing %>% 
  ggplot(aes(x=hourspw, y = tsales)) +
  geom_point() +
  geom_smooth(method = "lm", se = F) +
  labs(x = "Average hours worked Per Employee",
       y = "Total Sales",
       title = "Average Hours Worked and Total Sales") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))

clothing.lm <- lm(tsales ~ hourspw, data = Clothing)
summary(clothing.lm) %>% 
  pander()
```

$$
  \hat{Y}_i = ... 1745 + 43885X_i
$$

</div>


### Part (c) {}

Report the test statistics and p-values given by your summary(...) in R for the following hypotheses.

$$ 
  \begin{array}{l}
    H_0: \beta_0 = 0 \\
    H_a: \beta_0 \neq 0 \\
  \end{array} \quad 
  \begin{array}{l}
    H_0: \beta_1 = 0 \\
    H_a: \beta_1 \neq 0 \\
  \end{array}
$$

<div class="YourAnswer">

```{r}
summary(clothing.lm) %>% 
  pander()
```

--------------------------------------------
                    T Value       p-value
-------------    ------------   ------------
Intercept =        0.026          .979
Slope =            13.218         <2e-16
--------------------------------------------


</div> 
 
 
### Part (d) {}

Now, use your own calculations to obtain test statistics and p-values for the following hypotheses.

You may find useful information on how to do this in the "Explanation" tab under "t Tests" from your Math 325 Notebook, Simple Linear Regression page.

$$ 
  \begin{array}{l}
    H_0: \beta_0 = 1500 \\
    H_a: \beta_0 \neq 1500 \\
  \end{array} \quad 
  \begin{array}{l}
    H_0: \beta_1 = 35000 \\
    H_a: \beta_1 \neq 35000 \\
  \end{array}
$$

Note that these hypotheses come from previous knowledge about clothing sales and employee hours. They state that in years past, the average annual sales when no employees worked any hours on average, was 1500. And that as average eployee hours worked increases by 1 hour, the average total annual sales increases by 35,000. The question now, is if the earning pattern has changed from what it used to be.

<div class="YourAnswer">

```{r}
b_0 <- clothing.lm$coefficients[1]
b_1 <- clothing.lm$coefficients[2]

t_b0 <- (b_0 - 1500)/67479
t_b1 <- (b_1 - 35000)/67479

p_b0 <- pt(-abs(t_b0), 400)*2
p_b1 <- pt(-abs(t_b1), 400)*2

t_b0
t_b1
p_b0
p_b1

cv_q <- qt(.025,98)

cv_q*.4379




```

Type your answer here...

</div>  
 
### Part (e) {}

State the slope, y-intercept, and $R^2$ of this regression. Further, provide 95% confidence intervals for the slope and intercept. Interpret the values.

<div class="YourAnswer">

```{r}
summary(clothing.lm) %>% 
  pander()

cv2 <- qt(((1-.05)/2), 400-2)
```

--------------------------------------
                          Value   
------------      ------------------
Intercept =        1745
Slope =                  43885
$R^2$ =                 0.3051
--------------------------------------

This intercept is the value of the predicted total sales if the Average hours worked was 0, which isn't likely and thus the intercept is not important in this model
The slope is the predicted rate at which, in this case, increase for every 1 hour increase in average hours worked per employee.
The $R^2$ value tells us how well this model fits the data. Approaching 0 meaning that it doesn't fit well at all and approaching 1 meaning that it fits well. As you can see, this model isn't the best. 

With 400 degrees of freedom, our critical value = -0.06274633. Therefore our confidence intervals are:

$$
 \beta_1: \quad 43885 \pm `r cv2*3320`
$$
$$
 \beta_0: \quad 1745 \pm `r cv2*67479`
$$


</div>


### Part (f) {}

Create a residuals vs fitted-values plot and Q-Q Plot of the residuals for this regression. What do these plots show?

<div class="YourAnswer">

```{r}
clothing1 <- Clothing %>% 
  filter(tsales != 5000000)

clothing1.lm <- lm(tsales~hourspw, data = clothing1)
summary(clothing1.lm)


par(mfrow=c(1,3))
plot(clothing.lm, which=1)
qqPlot(clothing.lm$residuals, id = FALSE, main = "QQ Plot",
       ylab = "Residuals")
plot(clothing.lm$residuals, main = "Residuals vs Order", xlab="",ylab="Residuals")

par(mfrow=c(1,3))
plot(clothing1.lm, which=1)
qqPlot(clothing1.lm$residuals, id = FALSE, main = "QQ Plot",
       ylab = "Residuals")
plot(clothing1.lm$residuals, main = "Residuals vs Order", xlab="",ylab="Residuals")

clothing1.lm.t <- lm(tsales^(.25) ~ log(hourspw), data = clothing1)

b_0 <- clothing1.lm.t$coefficients[1]
b_1 <- clothing1.lm.t$coefficients[2]

clothing1 %>% 
  ggplot(aes(x= log(hourspw), y = tsales^(.25))) +
  geom_point() +
  stat_function(fun = function(x){(b_0 + b_1*x)}) +
  labs(x = "Average hours worked Per Employee",
       y = "Total Sales",
       title = "Average Hours Worked and Total Sales") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))


boxCox(clothing1.lm.t)

```
Honestly, all three plots show violated assumptions. The linearity is back, constant variance is terrible. The Normaily is way bad, and there are patterns in the Residuals vs Order

</div>
 

### Part (g) {}

Do any x-transformations or y-transformations improve the regression? If so, which ones?

<div class="YourAnswer">

```{r}
boxCox(clothing.lm)
```

It would appear that a $Y^\lambda$ transformation with $\lambda=0.5$ would be the best y-transformation in this case. And a log(X) would be the best x-transformation.

</div>



----







<style>

.YourAnswer {
  color: #317eac;
  padding: 10px;
  border-style: solid;
  border-width: 2px;
  border-color: skyblue4;
  border-radius: 5px;
}

</style>

 
 